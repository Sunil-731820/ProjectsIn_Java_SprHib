<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">KIE Tools Examples &amp;#8211; Implementing a Ping Pong View in Angular</title><link rel="alternate" href="https://blog.kie.org/2022/02/kie-tools-examples-implementing-a-ping-pong-view-in-angular.html" /><author><name>Thiago Lugli</name></author><id>https://blog.kie.org/2022/02/kie-tools-examples-implementing-a-ping-pong-view-in-angular.html</id><updated>2022-02-22T16:36:29Z</updated><content type="html">Following the on how to create custom views using our , we now expand these examples with a new view implementation, this time using Angular instead of React! In this post I’ll show how we refactored the Ping Pong View to be more generic and agnostic concerning the frontend framework used, then we’ll build an Angular implementation of the View, which can be rendered inside an IFRAME or a DIV (using !). Everything shown in this post was implemented in this PR to add new examples to our project and show that the Multiplying Architecture can be used with any framework. Photo by on REFACTORING THE PING PONG VIEW PACKAGE The first thing we had to do to make the Ping Pong View package agnostic to frontend frameworks was to, instead of taking full control of where and when to render an implementation, allow the implementation to render itself and initialize the API whenever it’s ready. In the following sections, we will see how each submodule of the Ping Pong View package was changed to support this architecture. APIS Few changes have been made to the APIs (Channel, Envelope, and external PingPongApi). The most noticeable one was the addition of new external and envelope methods to showcase how a Channel can control and obtain data from envelope implementations. This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. /** * The API of a PingPongViewApi. * * These methods are what the "external world" knows about this component. */ export interface PingPongApi { clearLogs(): void; getLastPingTimestamp(): Promise&lt;number&gt;; } hosted with ❤ by This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. /** * Methods provided by the Envelope that can be consumed by the Channel. */ export interface PingPongEnvelopeApi { pingPongView__init(association: Association, initArgs: PingPongInitArgs): Promise&lt;void&gt;; pingPongView__clearLogs(): Promise&lt;void&gt;; pingPongView__getLastPingTimestamp(): Promise&lt;number&gt;; } hosted with ❤ by ENVELOPE To start, no more “PingPongEnvelopeView.tsx” was needed since implementations would handle their rendering inside the provided container, so it was removed. This was an important and necessary step because Angular doesn’t have something similar to ReactDOM.render() that can render a React component wherever it’s called (but that can be solved with Web Components, as we will see shortly). The PingPongEnvelopeApiImpl also received some changes. The pingPongView__init() method doesn’t need to wait for the view implementation to render before calling its factory create() method anymore, since at the time it’s called the view is rendered and ready. This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. export class PingPongEnvelopeApiImpl implements PingPongEnvelopeApi { constructor( private readonly args: EnvelopeApiFactoryArgs&lt;PingPongEnvelopeApi, PingPongChannelApi, void, {}&gt;, private readonly pingPongViewFactory: PingPongFactory ) {} pingPongApi?: () =&gt; PingPongApi | null; public async pingPongView__init(association: Association, initArgs: PingPongInitArgs) { this.args.envelopeClient.associate(association.origin, association.envelopeServerId); this.pingPongApi = this.pingPongViewFactory.create(initArgs, this.args.envelopeClient.manager.clientApi); } public async pingPongView__clearLogs() { this.pingPongApi?.()?.clearLogs(); } public async pingPongView__getLastPingTimestamp() { const api = this.pingPongApi?.(); if (!api) return Promise.resolve(0); return api.getLastPingTimestamp(); } } hosted with ❤ by EMBEDDED Here are convenient React components to be used for integrating any Ping Pong View implementations. These components forward their refs, which, in this case, are the implementations of the PingPongApi, returned by the create() method from the PingPongFactory of your custom view. In the case of iFrames, the implementation should provide an entry point URL (the “envelopePath”). For DIVs, it should provide a “renderView” method that receives the container where it should be displayed and the envelope ID to be mapped. Once the view is rendered the envelope can be initialized via PingPongViewEnvelope.init(). One of the parameters passed should be an instance of the PingPongFactory from your implementation. This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. export class PingPongApiService implements PingPongFactory { … create(initArgs: PingPongInitArgs, channelApi: MessageBusClientApi&lt;PingPongChannelApi&gt;) { … return () =&gt; { … } as PingPongApi; } pingPongApiService = new PingPongApiService(); // Initialize envelope with the container config, the bus, // and factory (in this case, a service that implements the "create" method). // This should be called after the view is rendered, // inside a `ngOnInit` or `useEffect` for example. PingPongViewEnvelope.init({ config: { containerType: this.containerType, envelopeId: this.envelopeId! }, bus: { postMessage: (message, _targetOrigin, transfer) =&gt; window.parent.postMessage(message, "*", transfer) }, pingPongViewFactory: this.pingPongApiService, }); hosted with ❤ by IMPLEMENTING PING PONG VIEW IN ANGULAR Any Angular application, after being built, results in an index.html file that loads multiple .js files (polyfills.js, runtime.js, and main.js). This is fine when we are running the application by itself or inside an iFrame, but if we want to render it in a DIV (or any other HTML Element) Angular doesn’t provide a utility such as ReactDOM.render(). What it does provide is a simple way to create a Web Component that can be used anywhere! So in this section, we will see how to implement a Ping Pong View in Angular and then build a Web Component from an Angular application. THE APPLICATION If you are new to Angular, the from the Angular documentation is great! But don’t worry, we will start from the beginning, creating an Angular application from the ground up. First, make sure that you have angular/cli installed globally: npm install -g @angular/cli Now create a new Angular project with the following command: ng new ping-pong-view-angular (using Angular routing and any stylesheet formatting other than CSS is optional) You should get a template project like this! We can now go ahead and create our Ping Pong module with a component and service: cd src/app ng generate module ping-pong cd ping-pong ng generate component ping-pong --flat ng generate service ping-pong-api Great! Now, before implementing the component and service, let’s make sure that the ping-pong component is rendered correctly in our app component (which is the application entry point). For that, edit the app.component.html file, removing everything and adding the ping-pong component: &lt;app-ping-pong&gt;&lt;/app-ping-pong&gt; PING PONG API SERVICE In Angular, services can have many uses, the most common ones being to interface with external APIs and keep a state of values used across the application. For this project, we want to use the Channel API provided by the Envelope while keeping a local state of all pings and pongs sent and received. A great way to do this is to make the PingPongApiService class also implement the PingPongFactory interface, passing an instance of it to the PingPongViewEnvelope init() method (to later have our PingPongApiService create() being called inside PingPongEnvelopeApiImpl.pingPongView__init() passing the necessary initial arguments and the Client API). This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { Injectable } from "@angular/core"; import { MessageBusClientApi } from "@kie-tools-core/envelope-bus/dist/api"; import { PingPongChannelApi, PingPongInitArgs } from "@kie-tools-examples/ping-pong-view/dist/api"; import { PingPongFactory } from "@kie-tools-examples/ping-pong-view/dist/envelope"; import { ReplaySubject, BehaviorSubject, Subject } from "rxjs"; declare global { interface Window { initArgs: PingPongInitArgs; channelApi: PingPongChannelApi; } } export interface LogEntry { line: string; time: number; } function getCurrentTime() { return Date.now(); } @Injectable({ providedIn: 'root', }) export class PingPongApiService implements PingPongFactory { channelApi: MessageBusClientApi&lt;PingPongChannelApi&gt;; initArgs: PingPongInitArgs; log = new ReplaySubject&lt;LogEntry&gt;(10); logCleared = new Subject(); lastPingTimestamp = new BehaviorSubject&lt;number&gt;(0); dotInterval?: number; initialized = false; pingSubscription?: (source: string) =&gt; void; pongSubscription?: (source: string, replyingTo: string) =&gt; void; constructor() {} create(initArgs: PingPongInitArgs, channelApi: MessageBusClientApi&lt;PingPongChannelApi&gt;) { // Making sure we don't subscribe more than once. this.clearSubscriptions(); this.clearInterval(); this.initArgs = initArgs; this.channelApi = channelApi; // Subscribe to ping notifications. this.pingSubscription = this.channelApi.notifications.pingPongView__ping.subscribe((pingSource) =&gt; { // If this instance sent the PING, we ignore it. if (pingSource === this.initArgs.name) { return; } // Add a new line to our log, stating that we received a ping. this.log.next({ line: `PING from '${pingSource}'.`, time: getCurrentTime() }); // Acknowledges the PING message by sending back a PONG message. this.channelApi.notifications.pingPongView__pong.send(this.initArgs.name, pingSource); }); // Subscribe to pong notifications. this.pongSubscription = this.channelApi.notifications.pingPongView__pong.subscribe( (pongSource: string, replyingTo: string) =&gt; { // If this instance sent the PONG, or if this PONG was not meant to this instance, we ignore it. if (pongSource === this.initArgs.name || replyingTo !== this.initArgs.name) { return; } // Updates the log to show a feedback that a PONG message was observed. this.log.next({ line: `PONG from '${pongSource}'.`, time: getCurrentTime() }); } ); // Populate the log with a dot each 2 seconds. this.dotInterval = window.setInterval(() =&gt; { this.log.next({ line: ".", time: getCurrentTime() }); }, 2000); this.initialized = true; return () =&gt; ({ clearLogs: () =&gt; { this.log = new ReplaySubject&lt;LogEntry&gt;(10); // Emit a value to logCleared so we can re-subscribe to this.log wherever needed. this.logCleared.next(null); }, getLastPingTimestamp: () =&gt; { return Promise.resolve(this.lastPingTimestamp.value); }, }); } // Send a ping to the channel. ping() { this.channelApi.notifications.pingPongView__ping.send(this.initArgs.name); this.lastPingTimestamp.next(getCurrentTime()); } clearSubscriptions() { this.pingSubscription &amp;amp;&amp; this.channelApi.notifications.pingPongView__ping.unsubscribe(this.pingSubscription); this.pongSubscription &amp;amp;&amp; this.channelApi.notifications.pingPongView__pong.unsubscribe(this.pongSubscription); } clearInterval() { window.clearInterval(this.dotInterval); } ngOnDestroy() { this.clearSubscriptions(); this.clearInterval(); } } hosted with ❤ by PING PONG COMPONENT Our component should both initialize and consume the Ping Pong Api Service, and then, display the pings and pongs logs. This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { PingPongApiService, LogEntry } from "./ping-pong-api.service"; import { Component, Input, OnInit } from "@angular/core"; import * as PingPongViewEnvelope from "@kie-tools-examples/ping-pong-view/dist/envelope"; import { ContainerType } from "@kie-tools-core/envelope/dist/api"; import { Observable, scan } from "rxjs"; @Component({ selector: "app-ping-pong", templateUrl: "./ping-pong.component.html", styleUrls: ["./ping-pong.component.css"], providers: [], }) export class PingPongComponent implements OnInit { @Input() containerType: ContainerType = ContainerType.IFRAME; @Input() envelopeId?: string; constructor(public pingPongApiService: PingPongApiService) {} log: Observable&lt;LogEntry[]&gt;; subscribeToLogUpdates() { this.log = this.pingPongApiService.log.asObservable().pipe(scan((acc, curr) =&gt; […acc.slice(–9), curr], [])); } ngOnInit() { // Initialize log with a starting message. this.pingPongApiService.log.next({ line: "Logs will show up here", time: 0 }); // Initialize envelope with the container config, the bus, // and factory (in this case, a service that implements the "create" method). PingPongViewEnvelope.init({ config: { containerType: this.containerType, envelopeId: this.envelopeId! }, bus: { postMessage: (message, _targetOrigin, transfer) =&gt; window.parent.postMessage(message, "*", transfer) }, pingPongViewFactory: this.pingPongApiService, }); // Create an observable variable with the 10 latest values of the log. this.subscribeToLogUpdates(); this.pingPongApiService.logCleared.subscribe(() =&gt; this.subscribeToLogUpdates()); } } hosted with ❤ by Notice that the component has two Input() arguments, these arguments are the equivalent of props in a React component, and they serve to receive values from a parent component. They are needed here to differentiate when the ping-pong component is being rendered in a DIV or an iFrame. By default, it’ll assume it’s in an iFrame so these inputs don’t need to be set, but later on, we will see how to set them so that the component works as a Web Component. On init (via ngOnInit) the PingPongViewEnvelope is initialized, receiving the instance of our Ping Pong Api Service as a Ping Pong Factory, and at this point, the Channel and Envelope will start to communicate with each other. So far, so good! But we still need to display the ping pong logs somewhere! That’s where the ping-pong.component.html template file comes in. As long as it is mapped as the template file for the component, everything publicly available in the PingPongComponent class can be used in the template, like so: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. &lt;div class="ping-pong-view–main"&gt; &lt;h2&gt;This is an implementation of Ping-Pong View in Angular&lt;/h2&gt; &lt;p class="ping-pong-view–p-iframe"&gt; The envelope boundary border is green. It can be an iFrame or a Div. (It's possible to use Div if using web components made from Angular components) &lt;/p&gt; &lt;p class="ping-pong-view–p-ping-pong"&gt;The Ping-Pong View implementation border is red&lt;/p&gt; &lt;div class="ping-pong-view–container"&gt; &lt;i&gt;#{{ pingPongApiService.initArgs?.name }}&lt;/i&gt; &lt;div class="ping-pong-view–header"&gt; &lt;span&gt;Hello from Angular!&lt;/span&gt; &lt;button (click)="pingPongApiService.ping()"&gt;Ping others!&lt;/button&gt; &lt;/div&gt; &lt;div class="ping-pong-view–log"&gt; &lt;p *ngFor="let entry of log | async" class="ping-pong-view–line"&gt; {{ entry.line }} &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; hosted with ❤ by PING PONG MODULE Lastly, we can edit our ping-pong.module.ts file with everything we’ve just created: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { PingPongApiService } from "./ping-pong-api.service"; import { NgModule } from "@angular/core"; import { BrowserModule } from "@angular/platform-browser"; import { PingPongComponent } from "./ping-pong.component"; @NgModule({ declarations: [PingPongComponent], imports: [BrowserModule], exports: [PingPongComponent], providers: [PingPongApiService], bootstrap: [PingPongComponent], }) export class PingPongModule {} hosted with ❤ by And that’s it! We now have an Angular application running a Ping Pong View implementation! But how can it run in a DIV? BUILDING A WEB COMPONENT FROM AN ANGULAR APP When Angular 6 was released, along with it, was released a new utility package: angular/elements. It provides everything needed to build Web Components from Angular applications. You can read more about it ! This new tool now comes in handy for us, since our application so far is just a simple component and service. In the next steps, we will learn how to create a Web Component from an Angular module. WEB COMPONENT MODULE First, let’s create a new module with the following command at the root of our project: ng generate module web-component Then create a component in the web-component directory: cd src/app/web-component ng generate component web-component --flat WRAPPER COMPONENT The web-component.component.ts file should only be a wrapper for the Ping Pong component, passing the containerType and envelopeId inputs. This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { Component, Input } from "@angular/core"; import { ContainerType } from "@kie-tools-core/envelope/dist/api"; @Component({ selector: "ping-pong-wc", template: `&lt;app-ping-pong [containerType]="containerType" [envelopeId]="envelopeId"&gt;&lt;/app-ping-pong&gt;`, }) export class PingPongWcComponent { @Input("containertype") containerType: ContainerType; @Input("envelopeid") envelopeId: string; } hosted with ❤ by MODULE In the web-component.module.ts file is where the magic happens! That’s where we will take advantage of angular/elements to create a custom element (a.k.a Web Component). It should look something like this: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { NgModule, Injector, DoBootstrap } from "@angular/core"; import { BrowserModule } from "@angular/platform-browser"; import { createCustomElement } from "@angular/elements"; import { PingPongModule } from "../ping-pong/ping-pong.module"; import { PingPongWcComponent } from "./web-component.component"; @NgModule({ declarations: [PingPongWcComponent], imports: [BrowserModule, PingPongModule], entryComponents: [PingPongWcComponent], providers: [], }) export class WebComponentModule implements DoBootstrap { constructor(private injector: Injector) {} ngDoBootstrap() { const element = createCustomElement(PingPongWcComponent, { injector: this.injector }); customElements.define("ping-pong-angular", element); } } hosted with ❤ by THE WEB-COMPONENT BUILD Angular allows us to have multiple builds in the same project, this makes it possible to build multiple applications, packages, and libraries from a singular Angular project. This is great news for us because we want to build an Angular application to render in an iFrame, but we also want to build a Web Component, using the same components and services! Whenever we bootstrap a new Angular project a main.ts file is automatically generated, this is the application entry point, basically where the main module should be loaded to a web page (the App module by default). For our web component, we need a new and different main file, so that it can be the entry point for the component.  In the same folder of the web component module, create a file named web-component.main.ts with the following content: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { WebComponentModule } from "./web-component.module"; import { platformBrowserDynamic } from "@angular/platform-browser-dynamic"; const bootstrap = () =&gt; platformBrowserDynamic().bootstrapModule(WebComponentModule); bootstrap().catch((err) =&gt; console.error(err)); hosted with ❤ by It’s almost identical to the main.ts created by Angular, but it loads the WebComponentModule instead of the AppModule. But it’s not over yet, we need to declare this new project so that angular/cli can figure out how to build it. This is where we edit the angular.json file, adding a new “project” to it, alongside the ping-pong-view-angular one. Let’s call it “ping-pong-view-wc”: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. { "$schema": "./node_modules/@angular/cli/lib/config/schema.json", "version": 1, "newProjectRoot": "projects", "cli": { "packageManager": "yarn" }, "projects": { "ping-pong-view-angular": { … }, "ping-pong-view-wc": { "projectType": "application", "root": "", "sourceRoot": "src", "architect": { "build": { "builder": "@angular-devkit/build-angular:browser", "options": { "outputPath": "dist/wc", "index": "src/index.html", "main": "src/app/web-component/web-component.main.ts", "polyfills": "src/polyfills.ts", "tsConfig": "tsconfig.wc.json", "aot": true, "assets": ["src/favicon.ico", "src/assets"], "styles": ["src/styles.css"], "scripts": [] }, "configurations": { "production": { "fileReplacements": [ { "replace": "src/environments/environment.ts", "with": "src/environments/environment.prod.ts" } ], "optimization": true, "outputHashing": "none", "sourceMap": false, "namedChunks": false, "extractLicenses": true, "vendorChunk": false, "buildOptimizer": true, "budgets": [ { "type": "initial", "maximumWarning": "500kb", "maximumError": "1mb" }, { "type": "anyComponentStyle", "maximumWarning": "2kb", "maximumError": "4kb" } ] } } } } } }, "defaultProject": "ping-pong-view-angular" } hosted with ❤ by It’s important to create a new tsconfig file specifically for this new build so that the correct files are included and the build is output to a new directory: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. { "extends": "./tsconfig.json", "compilerOptions": { "outDir": "./dist/wc", "types": [] }, "files": ["src/app/web-component/web-component.main.ts", "src/polyfills.ts"], "include": ["src/app/web-component/*.d.ts"] } hosted with ❤ by BUILD SCRIPTS Finally is time to build our Web Component, and for that new scripts can be added to your package.json: "scripts": { ... "build:wc": "ng build ping-pong-view-wc &amp;amp;&amp; yarn run build:wc:concat", "build:wc:concat": "cat dist/wc/polyfills.js dist/wc/runtime.js dist/wc/main.js &gt; dist/wc/index.js", ... } The “build:wc:concat” command is useful to generate a single file to be loaded wherever this web-component is used, making it simple to use, instead of loading all 3 files every time. That’s it, we’re finally done, right? Well, not quite… MULTIPLE PING-PONG-VIEW WEB COMPONENTS ON THE SAME PAGE What would happen if we loaded multiple ping-pong-view web components on the same page? In theory, everything should be fine, because all web components should be self-contained. And they are! But , and without any changes, every ping-pong web component will be using the same instance of the PingPongApiService. Thankfully, Angular provides an easy way to fix that! Remember our ping-pong-api.service.ts? It declares an Angular service that implements the PingPongFactory interface, but by default, Angular makes it an Injectable service that is provided in the “root” of our project, like this: @Injectable({ providedIn: 'root', }) export class PingPongApiService implements PingPongFactory { ... Well, to make it not behave as a singleton, we just need to remove the “providedIn” property: @Injectable() export class PingPongApiService implements PingPongFactory { ... And, so that our component can still inject the service as its dependency, we need to set it as a provider. In the ping-pong.component.ts file add PingPongApiService as a Provider like this: @Component({ selector: "app-ping-pong", templateUrl: "./ping-pong.component.html", styleUrls: ["./ping-pong.component.css"], providers: [PingPongApiService], }) export class PingPongComponent implements OnInit { ... And now we are finally done! As long as you load the built index.js file as a script wherever you want (even inside a React component) you can load the web component by its name: &lt;ping-pong-angular containerType="div" envelopeId="..."&gt;&lt;/ping-pong-angular&gt; Congrats on building your Angular application implementing a Ping Pong View! If you have any questions feel free to post in the comments section below. Also, check out the original implementation in our project, along with the one made entirely in React! The post appeared first on .</content><dc:creator>Thiago Lugli</dc:creator></entry><entry><title>Debug .NET applications running in local containers with VS Code</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/02/22/debug-net-applications-running-local-containers-vs-code" /><author><name>Tom Deseyn</name></author><id>ecb647fb-440f-483b-a75f-b0d73a7775ed</id><updated>2022-02-22T07:00:00Z</updated><published>2022-02-22T07:00:00Z</published><summary type="html">&lt;p&gt;A &lt;a href="https://developers.redhat.com/articles/2022/01/07/debug-net-applications-running-kubernetes-vs-code"&gt;previous article&lt;/a&gt; showed how to debug a &lt;a href="https://developers.redhat.com/topics/dotnet"&gt;.NET&lt;/a&gt; application that is running on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; from &lt;a href="https://code.visualstudio.com"&gt;Visual Studio Code&lt;/a&gt; (VS Code) on your local development machine. In this tutorial, you'll debug an application that is running in a &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; right on your development machine.&lt;/p&gt; &lt;h2&gt;Use cases&lt;/h2&gt; &lt;p&gt;If you plan to deploy your application on Kubernetes, the application will run in a container. Debugging the application in a local container can let you see its behavior in a local environment that is fairly close to the production environment.&lt;/p&gt; &lt;p&gt;Even when you don't intend to deploy your application using containers, running it in a container can be a way to reproduce a bug that is reported to occur only in a specific environment, such as a specific Linux distribution.&lt;/p&gt; &lt;h2&gt;Choices for building an image&lt;/h2&gt; &lt;p&gt;The image for our debug session needs to provide .NET runtime dependencies. You can build an image yourself or base it on images provided by Microsoft (through &lt;a href="https://hub.docker.com/_/microsoft-dotnet-runtime"&gt;runtime images&lt;/a&gt; or &lt;a href="https://hub.docker.com/_/microsoft-dotnet-sdk"&gt;SDK images&lt;/a&gt;) or Red Hat (through &lt;a href="https://catalog.redhat.com/software/containers/search?q=%27.NET%20Runtime%20Only%27&amp;p=1"&gt;runtime images&lt;/a&gt; or &lt;a href="https://catalog.redhat.com/software/containers/search?q=%27.NET%20SDK%27&amp;p=1"&gt;SDK images&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;Red Hat provides Universal Base Images (UBI) for .NET. These are enterprise-grade images that can be freely distributed and deployed anywhere. Take a look at the &lt;a href="https://developers.redhat.com/articles/ubi-faq"&gt;UBI FAQ&lt;/a&gt; or read the e-book &lt;a href="https://developers.redhat.com/e-books/red-hat-universal-base-images-ubi"&gt;&lt;em&gt;Red Hat Universal Base Images (UBI)&lt;/em&gt;&lt;/a&gt; to learn more.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;If you haven't already, install Visual Studio Code using the instructions on the project's &lt;a href="https://code.visualstudio.com/"&gt;website&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Next, launch VS Code and install the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.csharp"&gt;C# extension&lt;/a&gt; and &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker"&gt;Docker extension&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;You also need to install a container engine such as &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; or &lt;a href="https://podman.io/"&gt;Podman&lt;/a&gt;. I'm using Podman, which comes pre-installed on Fedora. The VS Code Docker extension doesn't detect Podman automatically, though. The rest of this section shows how you can configure the use of Podman. If you are using Docker, you can skip to the next section.&lt;/p&gt; &lt;p&gt;First, enable the &lt;code&gt;podman.socket&lt;/code&gt; service, which provides a Docker-compatible API:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ sudo dnf install podman-remote $ systemctl --user enable --now podman.socket&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In VS Code, open the &lt;strong&gt;Command Palette&lt;/strong&gt; by pressing Ctrl+Shift+P and choose &lt;strong&gt;Preferences: Open Settings (JSON)&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;Add the following settings:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;{ "docker.dockerPath": "podman", "docker.host": "unix:///run/user/1000/podman/podman.sock" }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The first setting tells the extension to use the &lt;code&gt;podman&lt;/code&gt; executable instead of &lt;code&gt;docker&lt;/code&gt;. The other setting provides the path to the API socket. The value &lt;code&gt;1000&lt;/code&gt; needs to match your user ID (UID). You can see your UID by running &lt;code&gt;id -u&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Debug the application&lt;/h2&gt; &lt;p&gt;Open your application folder in VS Code. If you don't have an application, you can create one as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ dotnet new web -o web $ cd web $ code .&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now open the &lt;strong&gt;Command Palette&lt;/strong&gt; by pressing Ctrl+Shift+P and choose &lt;strong&gt;Docker: Add Docker Files to Workspace...&lt;/strong&gt;. (Figure 1).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/add-dockerfile.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/add-dockerfile.png?itok=TrR8E938" width="290" height="103" alt="The Command Palette in VS Code, with the proper extensions, lets you add Docker or Podman files." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. The Command Palette in VS Code, with the proper extensions, lets you add Docker or Podman files. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The IDE prompts you with some questions:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;As the application platform, choose .NET ASP.NET Core.&lt;/li&gt; &lt;li&gt;When prompted to select an operating system, pick your host OS (Windows/Linux).&lt;/li&gt; &lt;li&gt;Next, specify a comma-separated list of ports to expose. I suggest specifying &lt;code&gt;5000,8080&lt;/code&gt; because those are the ports used by the Microsoft and Red Hat images.&lt;/li&gt; &lt;li&gt;Finally, answer No when asked to add the optional Docker Compose file.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;The IDE will add a debug configuration to &lt;code&gt;.vscode/launch.json&lt;/code&gt; to launch the application in a container. The &lt;code&gt;.vscode/tasks.json&lt;/code&gt; file contains a few tasks that are used in this process:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;The docker-run: debug&lt;/code&gt; task launches the container.&lt;/li&gt; &lt;li&gt;&lt;code&gt;The docker-build: debug&lt;/code&gt; task builds the container.&lt;/li&gt; &lt;li&gt;The usual &lt;code&gt;build&lt;/code&gt; task builds the application on the host.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The &lt;code&gt;docker-build&lt;/code&gt; step uses the &lt;code&gt;Dockerfile&lt;/code&gt; that was added to the workspace. The &lt;code&gt;base&lt;/code&gt; image defined in this file is used for debugging. Change the configuration to use a UBI image by replacing all the lines starting with the &lt;code&gt;FROM … as build&lt;/code&gt; line with the following:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;FROM registry.access.redhat.com/ubi8/dotnet-60-runtime AS base&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you're not using .NET 6.0, you need to update the &lt;code&gt;FROM&lt;/code&gt; image so it provides the right version.&lt;/p&gt; &lt;p&gt;If you are using the Red Hat image for an earlier .NET version than 6.0, you need to add the following additional line:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;CMD [ "bash" ]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can now launch your application In VS Code's &lt;strong&gt;Run and Debug&lt;/strong&gt; tab. Choose the &lt;strong&gt;Docker .NET Core Launch option&lt;/strong&gt; (Figure 2).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/launch-config.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/launch-config.png?itok=HL7cNdwY" width="334" height="174" alt="The Run and Debug tab in VS Code lets you run your application." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. The Run and Debug tab in VS Code lets you run your application. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The application will launch in the container with the debugger attached. You can add a breakpoint and hit it in the debugger (Figure 3).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/debug_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/debug_0.png?itok=lKPb0mwD" width="642" height="253" alt="The VS Code debugger has stopped the application at a breakpoint." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3. The VS Code debugger has stopped the application at a breakpoint. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;VS Code is designed for .NET and is extremely valuable for developing and debugging .NET applications. It saves a lot of time if you can debug in similar ways on your local system and in the cloud, running your application in a container in both cases. This approach helps you achieve that flexibility.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/02/22/debug-net-applications-running-local-containers-vs-code" title="Debug .NET applications running in local containers with VS Code"&gt;Debug .NET applications running in local containers with VS Code&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Tom Deseyn</dc:creator><dc:date>2022-02-22T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus Superheroes to the Rescue!</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-superheroes-to-the-rescue/" /><author><name>Eric Deandrea</name></author><id>https://quarkus.io/blog/quarkus-superheroes-to-the-rescue/</id><updated>2022-02-22T00:00:00Z</updated><content type="html">Are you a developer building microservices? Do you struggle with developing and testing individual microservices that are part of a larger system? Do you want to learn about building REST-based and event-driven applications? Introduction Quarkus has excellent documentation and quickstarts to help developers become familiar with various features in the...</content><dc:creator>Eric Deandrea</dc:creator></entry><entry><title type="html">Kogito 1.17.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/02/kogito-1-17-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/02/kogito-1-17-0-released.html</id><updated>2022-02-21T08:02:01Z</updated><content type="html">We are glad to announce that the Kogito 1.17.0 release is now available! This goes hand in hand with , release. From a feature point of view, we included a series of new features and bug fixes, including: * Data Index support to Oracle database (thanks for the contribution) * Added use cases to examples to see the Management and Task consoles working with PostgreSQL persistence:  and   * Serverless Workflow supports implementation * Serverless Workflow supports implementation * Serverless Workflow “useData” and “useResults” for events and actions. BREAKING CHANGES * Kogito Serverless Workflow Implementation has been upgraded to . Please update your workflow files to align with the updated DSL. For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.16.0 artifacts are available at the . A detailed changelog for 1.17.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title type="html">Getting started with Keycloak powered by Quarkus</title><link rel="alternate" href="http://www.mastertheboss.com/keycloak/getting-started-with-keycloak-powered-by-quarkus/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/keycloak/getting-started-with-keycloak-powered-by-quarkus/</id><updated>2022-02-17T11:34:58Z</updated><content type="html">This article covers the updates in Keycloak which now runs on top of Quarkus. The former (WildFly) distribution of Keycloak is deprecated so you should promptly start the migration process. Keycloak overview Keycloak is an Identity Provider that enables you to secure your Web applications by providing Single Sign-On (SSO) capabilities and leveraging industry standards ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Quality testing the Linux kernel</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/02/17/quality-testing-linux-kernel" /><author><name>Jeff Bastian</name></author><id>0eddae24-8b03-4454-a4ad-a662012f8390</id><updated>2022-02-17T07:00:00Z</updated><published>2022-02-17T07:00:00Z</published><summary type="html">&lt;p&gt;As a kernel quality engineer at Red Hat, I'm often asked what I do. How does one test a kernel for quality? Testing and debugging the Linux kernel can be challenging because you can't simply attach a debugger like GDB (the GNU Project debugger) if the kernel is crashing: When that happens, everything crashes, including GDB! Even if the kernel isn't crashing, if you ask a debugger to stop the kernel from running so you can inspect something, there is no way to resume running the kernel because the kernel itself is in charge of stopping and starting processes. Asking the kernel to stop itself is a dead-end road.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; There is a way to attach a debugger and stop and resume a kernel, but it requires a second computer and special hardware such as JTAG. Most of the time, I don't have access to that hardware, so that's out of the question.&lt;/p&gt; &lt;p&gt;Many people think that quality testing the Linux kernel must involve writing lots of kernel code; for example, a module to exercise a part of the kernel. Although that is a possibility, most testing actually happens from userspace. I spend a lot of time &lt;em&gt;reading&lt;/em&gt; kernel code to try to devise a test that usually runs as a simple Bash script. There are many ways to interact with the kernel from userspace, including system calls, logs, the &lt;code&gt;procfs&lt;/code&gt; and &lt;code&gt;sysfs&lt;/code&gt; virtual file systems, and more. In this article, I will introduce you to some of the simple tools I've used for investigating behavior in the Linux kernel.&lt;/p&gt; &lt;h2&gt;dmesg and journalctl&lt;/h2&gt; &lt;p&gt;The most basic check on Linux kernel operations, particularly to follow what they're doing with devices and modules, is to retrieve the messages that the kernel generates during its boot and later. The messages can be retrieved from the kernel's logs through a &lt;a href="https://www.linux.org/docs/man1/dmesg.html"&gt;dmesg&lt;/a&gt; or &lt;a href="https://www.linux.org/docs/man1/journalctl.html"&gt;journalctl&lt;/a&gt; command.&lt;/p&gt; &lt;p&gt;For instance, a feature I tested recently involved enabling support for &lt;a href="https://www.kernel.org/doc/html/latest/x86/amd-memory-encryption.html"&gt;AMD Secure Memory Encryption&lt;/a&gt; ( (SME) on AMD's latest CPUs. To enable SME, you have to add &lt;code&gt;mem_encrypt=on&lt;/code&gt; as a kernel parameter and reboot. You can then check for the string "sme" in the &lt;code&gt;dmesg&lt;/code&gt; logs. See the &lt;code&gt;/usr/share/doc/kernel-doc-4.18.0/Documentation/x86/amd-memory-encryption.txt&lt;/code&gt; file from the &lt;code&gt;kernel-doc&lt;/code&gt; RPM in &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) 8 for more information.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: You may need to enable SME in your BIOS settings, too.&lt;/p&gt; &lt;h3&gt;Enabling SME in dmesg logs&lt;/h3&gt; &lt;p&gt;Let's take a look at the steps to enable SME in dmesg logs.&lt;/p&gt; &lt;p&gt;First, by default, because &lt;code&gt;mem_encrypt&lt;/code&gt; is unset, &lt;code&gt;dmesg&lt;/code&gt; shows no messages:&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt;~]# dmesg | grep -i sme ~]# &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add the kernel parameter and reboot, and the message is logged:&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt;~]# grubby --args="mem_encrypt=on" --update-kernel=ALL ~]# reboot ... ~]# dmesg | grep -i sme [ 0.001000] AMD Memory Encryption Features active: SME &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To double-check your work, you can remove the parameter and reboot once more to verify that the message does &lt;em&gt;not&lt;/em&gt; show up in the logs:&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt;~]# grubby --remove-args="mem_encrypt=on" --update-kernel=ALL ~]# reboot ... ~]# dmesg | grep -i sme ~]# &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Further testing could be required to show that SME is working as expected, but the &lt;code&gt;dmesg&lt;/code&gt; logs give the first evidence that the kernel is properly detecting the hardware feature and enabling support when requested.&lt;/p&gt; &lt;h3&gt;Logging with journalctl&lt;/h3&gt; &lt;p&gt;I mentioned earlier that &lt;code&gt;journalctl&lt;/code&gt; can get the same output as &lt;code&gt;dmesg&lt;/code&gt;. This is because the journal recorded by &lt;code&gt;systemd&lt;/code&gt; includes the normal &lt;code&gt;dmesg&lt;/code&gt; logs along with userspace logs from &lt;code&gt;/var/log/messages&lt;/code&gt; and more, and each entry is annotated with metadata. To extract just the &lt;code&gt;dmesg&lt;/code&gt; equivalent from the journal, enter:&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt;~]# journalctl --dmesg --output short-monotonic --no-hostname -- Logs begin at Wed 2021-05-26 11:08:19 EDT, end at Wed 2021-05-26 17:01:01 EDT. -- [ 0.000000] kernel: Linux version 4.18.0-305.el8.x86_64 (mockbuild@x86-vm-07.build.eng.bos.redhat.com) (gcc version 8.4.1 20200928 (Red Hat 8.4.1-1) (GCC)) #1 SMP Thu Apr 29 08:54:30 EDT 2021 [ 0.000000] kernel: Command line: BOOT_IMAGE=(hd0,gpt2)/vmlinuz-4.18.0-305.el8.x86_64 root=/dev/mapper/rhel_dell--per7425--02-root ro crashkernel=auto resume=/dev/mapper/rhel_dell--per7425--02-swap rd.lvm.lv=rhel_dell-per7425-02/root rd.lvm.lv=rhel_dell-per7425-02/swap console=ttyS0,115200n81 [ 0.000000] kernel: x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers' [ 0.000000] kernel: x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers' [ 0.000000] kernel: x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers' [ 0.000000] kernel: x86/fpu: xstate_offset[2]: 576, xstate_sizes[2]: 256 [ 0.000000] kernel: x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using 'compacted' format. [ 0.000000] kernel: BIOS-provided physical RAM map: [ 0.000000] kernel: BIOS-e820: [mem 0x0000000000000000-0x000000000008efff] usable [ 0.000000] kernel: BIOS-e820: [mem 0x000000000008f000-0x000000000008ffff] ACPI NVS ... ... &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Compare the previous &lt;code&gt;journalctl&lt;/code&gt; output to &lt;code&gt;dmesg&lt;/code&gt; output:&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt;~]# dmesg [ 0.000000] Linux version 4.18.0-305.el8.x86_64 (mockbuild@x86-vm-07.build.eng.bos.redhat.com) (gcc version 8.4.1 20200928 (Red Hat 8.4.1-1) (GCC)) #1 SMP Thu Apr 29 08:54:30 EDT 2021 [ 0.000000] Command line: BOOT_IMAGE=(hd0,gpt2)/vmlinuz-4.18.0-305.el8.x86_64 root=/dev/mapper/rhel_dell--per7425--02-root ro crashkernel=auto resume=/dev/mapper/rhel_dell--per7425--02-swap rd.lvm.lv=rhel_dell-per7425-02/root rd.lvm.lv=rhel_dell-per7425-02/swap console=ttyS0,115200n81 [ 0.000000] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers' [ 0.000000] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers' [ 0.000000] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers' [ 0.000000] x86/fpu: xstate_offset[2]: 576, xstate_sizes[2]: 256 [ 0.000000] x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using 'compacted' format. [ 0.000000] BIOS-provided physical RAM map: [ 0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000008efff] usable [ 0.000000] BIOS-e820: [mem 0x000000000008f000-0x000000000008ffff] ACPI NVS ... ... &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The two commmands show nearly identical output. The differences are that &lt;code&gt;journalctl&lt;/code&gt; output starts with a &lt;code&gt;-- Logs begin&lt;/code&gt; line and shows the source of each message (the &lt;code&gt;kernel:&lt;/code&gt; prefix before each message).&lt;/p&gt; &lt;h2&gt;sysfs and procfs&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;/sys&lt;/code&gt; directory (&lt;em&gt;aka&lt;/em&gt; &lt;code&gt;sysfs&lt;/code&gt;) and &lt;code&gt;/proc&lt;/code&gt; directory (&lt;em&gt;aka&lt;/em&gt; &lt;code&gt;procfs&lt;/code&gt;) are also important sources of kernel information, and can be used to control the kernel.&lt;/p&gt; &lt;p&gt;As an example, an important feature of some servers is the ability to hot plug CPUs. Before you swap out a CPU, though, you have to tell the kernel to disable that CPU, or the kernel might try to schedule work on a CPU that's in the middle of being swapped.&lt;/p&gt; &lt;p&gt;Let's look at the preparation to hot swap a CPU.&lt;/p&gt; &lt;h3&gt;Disable a CPU for hot swapping&lt;/h3&gt; &lt;p&gt;We start with an &lt;a href="https://www.linux.org/docs/man1/lscpu.html"&gt;&lt;code&gt;lscpu&lt;/code&gt;&lt;/a&gt; command, which lists information about the CPUs, to find what CPUs we have with NUMA support. Then, we disable CPU 11 and check the CPU status again:&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt;~]# lscpu | grep 'CPU(s)' | grep -v NUMA CPU(s): 96 On-line CPU(s) list: 0-95 ~]# echo 0 &gt; /sys/devices/system/cpu/cpu11/online ~]# lscpu | grep 'CPU(s)' | grep -v NUMA CPU(s): 96 On-line CPU(s) list: 0-10,12-95 Off-line CPU(s) list: 11 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;A good way to double-check that the kernel is not trying to use CPU 11 is to verify that no interrupt handlers are assigned to it. To do this check, view the &lt;code&gt;/proc/interrupts&lt;/code&gt; file (the output is truncated here for better visibility):&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt;~]# less -SFiX /proc/interrupts CPU0 .... CPU9 CPU10 CPU12 CPU13 C&gt; 0: 169 .... 0 0 0 0 &gt; 4: 0 .... 0 0 0 0 &gt; 8: 0 .... 0 0 0 0 &gt; 9: 0 .... 0 0 0 0 &gt; 10: 0 .... 0 0 0 0 &gt; ... ... &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that the entire column for &lt;code&gt;CPU11&lt;/code&gt; is missing.&lt;/p&gt; &lt;p&gt;After hot-swapping CPU 11 for a new one, turn it back on:&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt;~]# echo 1 &gt; /sys/devices/system/cpu/cpu11/online ~]# lscpu | grep 'CPU(s)' | grep -v NUMA CPU(s): 96 On-line CPU(s) list: 0-95 ~]# less -SFiX /proc/interrupts CPU0 .... CPU9 CPU10 CPU11 CPU12 C&gt; 0: 169 .... 0 0 0 0 &gt; 4: 0 .... 0 0 0 0 &gt; 8: 0 .... 0 0 0 0 &gt; 9: 0 .... 0 0 0 0 &gt; 10: 0 .... 0 0 0 0 &gt; ... ... &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;CPU 11 is online and ready to process interrupts again.&lt;/p&gt; &lt;h3&gt;Disable CPU threads and cores&lt;/h3&gt; &lt;p&gt;Of course, modern CPUs have more than one core on each CPU, and each core can have two or more threads, so you'll need to disable all of the threads and cores on a CPU (or "socket") in order to hot swap it. The CPU topology on this particular system is:&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt;~]# lscpu | grep -e 'Thread(s)' -e 'Core(s)' -e 'Socket(s)' Thread(s) per core: 2 Core(s) per socket: 24 Socket(s): 2 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;So, to hot swap CPU 11 (that is, one thread of one core), we'll need to disable all of its siblings. This information is also available in &lt;code&gt;sysfs&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt;~]# cat /sys/devices/system/cpu/cpu11/topology/core_siblings_list 1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Disable all 48 of these CPUs, and then the system is ready for the physical CPU hot swap.&lt;/p&gt; &lt;h2&gt;crash&lt;/h2&gt; &lt;p&gt;Several years ago, I added support for the &lt;code&gt;RDRAND&lt;/code&gt; assembly instruction to the kernel for Intel's Ivy Bridge line of CPUs. As I mentioned at the start of this article, it's difficult to attach a debugger to the kernel, so I can't just single-step through the assembly code and look for executions of &lt;code&gt;RDRAND&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;I looked at the &lt;a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=628c6246d47b85f5357298601df2444d7f4dd3fd"&gt;upstream commit&lt;/a&gt; that enabled &lt;code&gt;RDRAND&lt;/code&gt; support and noticed a macro named &lt;code&gt;alternative_io&lt;/code&gt; that I had not seen before:&lt;/p&gt; &lt;pre&gt;&lt;code class="c"&gt; alternative_io("movl $0, %0\n\t" \ nop, \ "\n1: " rdrand "\n\t" \ "jc 2f\n\t" \ "decl %0\n\t" \ "jnz 1b\n\t" \ "2:", \ X86_FEATURE_RDRAND, \ ASM_OUTPUT2("=r" (ok), "=a" (*v)), \ "0" (RDRAND_RETRY_LOOPS)); \ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After &lt;a href="https://lwn.net/Articles/164121/"&gt;a bit of research&lt;/a&gt;, I learned that the &lt;code&gt;alternative&lt;/code&gt; set of macros (including variants like the &lt;code&gt;alternative_io&lt;/code&gt; macro shown here) is a mechanism for the kernel to do live patching on itself at boot under certain conditions. As background, a default set of fairly generic assembly instructions is compatible with all x86 CPUs going back to at least the Pentium (and likely back to 80386). But for newer CPUs that support a given hardware feature—&lt;code&gt;X86_FEATURE_RDRAND&lt;/code&gt;, in this case—the kernel rewrites those default instructions with the &lt;code&gt;alternative&lt;/code&gt; code. It does the rewrite on the fly while the kernel is booting.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;alternative&lt;/code&gt; macros are a very cool feature, much more efficient than using an &lt;code&gt;if&lt;/code&gt; statement. A simple approach to this problem, in the absence of &lt;code&gt;alternative&lt;/code&gt; macros, might look like the following (in pseudo-code):&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt; if (CPU does not have feature foo) then generic compatible slow code else fast new code endif &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The problem with this code is that the &lt;code&gt;if&lt;/code&gt; statement has to be evaluated every time this chunk of code is executed, and branch mispredictions are terrible for CPU performance. Modifying the instructions in-place avoids the branches.&lt;/p&gt; &lt;h3&gt;Kernel on disk with RDRAND support&lt;/h3&gt; &lt;p&gt;Let's use &lt;a href="https://man7.org/linux/man-pages/man1/objdump.1.html"&gt;&lt;code&gt;objdump&lt;/code&gt;&lt;/a&gt; to look at the &lt;code&gt;get_random_int&lt;/code&gt; function, along with the alternate instructions section, &lt;code&gt;altinstr_replacement&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="java bash numberLines"&gt;~]# objdump -d /usr/lib/debug/lib/modules/2.6.32-279.el6.x86_64/vmlinux ... ... ffffffff81313780 &lt;get_random_int&gt;: ffffffff81313780: 55 push %rbp ffffffff81313781: 48 89 e5 mov %rsp,%rbp ffffffff81313784: 48 83 ec 20 sub $0x20,%rsp ffffffff81313788: 48 89 5d e8 mov %rbx,-0x18(%rbp) ffffffff8131378c: 4c 89 65 f0 mov %r12,-0x10(%rbp) ffffffff81313790: 4c 89 6d f8 mov %r13,-0x8(%rbp) ffffffff81313794: e8 27 76 cf ff callq ffffffff8100adc0 &lt;mcount&gt; ffffffff81313799: ba 0a 00 00 00 mov $0xa,%edx ffffffff8131379e: ba 00 00 00 00 mov $0x0,%edx ffffffff813137a3: 66 66 66 90 data32 data32 xchg %ax,%ax ffffffff813137a7: 85 d2 test %edx,%edx ffffffff813137a9: 75 50 jne ffffffff813137fb &lt;get_random_int+0x7b&gt; ffffffff813137ab: 65 48 8b 1c 25 b0 e0 mov %gs:0xe0b0,%rbx ... ... ffffffff81d3db6c &lt;.altinstr_replacement&gt;: ... ... ffffffff81d407e7: 48 0f c7 f0 rdrand %rax ffffffff81d407eb: 72 04 jb ffffffff81d407f1 &lt;__alt_instructions_end+0x2c85&gt; ffffffff81d407ed: ff c9 dec %ecx ffffffff81d407ef: 75 f6 jne ffffffff81d407e7 &lt;__alt_instructions_end+0x2c7b&gt; ... ... &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this &lt;code&gt;objdump&lt;/code&gt; output, the following two lines are the default instructions from the &lt;code&gt;alternative_io&lt;/code&gt; macro:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ffffffff8131379e: ba 00 00 00 00 mov $0x0,%edx ffffffff813137a3: 66 66 66 90 data32 data32 xchg %ax,%ax &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And the &lt;code&gt;.altinstr_replacement&lt;/code&gt; section contains the instructions to use in their place if the hardware supports &lt;code&gt;RDRAND&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ffffffff81d407e7: 48 0f c7 f0 rdrand %rax ffffffff81d407eb: 72 04 jb ffffffff81d407f1 &lt;__alt_instructions_end+0x2c85&gt; ffffffff81d407ed: ff c9 dec %ecx ffffffff81d407ef: 75 f6 jne ffffffff81d407e7 &lt;__alt_instructions_end+0x2c7b&gt; &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Kernel in live RAM with RDRAND support&lt;/h3&gt; &lt;p&gt;Now we'll see the assembly language for the &lt;code&gt;get_random_int&lt;/code&gt; function in the running kernel. To be able to run the following command, install the &lt;a href="https://man7.org/linux/man-pages/man8/crash.8.html"&gt;&lt;code&gt;crash&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;gdb&lt;/code&gt;, and matching &lt;code&gt;kernel-debuginfo&lt;/code&gt; RPMs:&lt;/p&gt; &lt;pre&gt;&lt;code class="java bash numberLines"&gt;~]# crash -s /usr/lib/debug/lib/modules/2.6.32-279.el6.x86_64/vmlinux crash&gt; disassemble get_random_int Dump of assembler code for function get_random_int: 0xffffffff81313780 &lt;+0&gt;: push %rbp 0xffffffff81313781 &lt;+1&gt;: mov %rsp,%rbp 0xffffffff81313784 &lt;+4&gt;: sub $0x20,%rsp 0xffffffff81313788 &lt;+8&gt;: mov %rbx,-0x18(%rbp) 0xffffffff8131378c &lt;+12&gt;: mov %r12,-0x10(%rbp) 0xffffffff81313790 &lt;+16&gt;: mov %r13,-0x8(%rbp) 0xffffffff81313794 &lt;+20&gt;: nopl 0x0(%rax,%rax,1) 0xffffffff81313799 &lt;+25&gt;: mov $0xa,%edx 0xffffffff8131379e &lt;+30&gt;: rdrand %eax 0xffffffff813137a1 &lt;+33&gt;: jb 0xffffffff813137a7 &lt;get_random_int+39&gt; 0xffffffff813137a3 &lt;+35&gt;: dec %edx 0xffffffff813137a5 &lt;+37&gt;: jne 0xffffffff8131379e &lt;get_random_int+30&gt; ... End of assembler dump. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The kernel recognized at boot that it had &lt;code&gt;RDRAND&lt;/code&gt; support, so it inserted the four lines in the &lt;code&gt;.altinstr_replacement&lt;/code&gt; section.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;jc&lt;/code&gt;, &lt;code&gt;decl&lt;/code&gt;, and &lt;code&gt;jnz&lt;/code&gt; instructions were decoded by &lt;code&gt;crash&lt;/code&gt; into the functionally equivalent &lt;code&gt;jb&lt;/code&gt;, &lt;code&gt;dec&lt;/code&gt;, and &lt;code&gt;jne&lt;/code&gt; instructions, but that's a topic for another day.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article was a quick introduction to some of the tools I have used to quality test the Linux kernel in userspace.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/02/17/quality-testing-linux-kernel" title="Quality testing the Linux kernel"&gt;Quality testing the Linux kernel&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Jeff Bastian</dc:creator><dc:date>2022-02-17T07:00:00Z</dc:date></entry><entry><title type="html">Kubernetes Service Discovery and Selection with Stork</title><link rel="alternate" href="https://quarkus.io/blog/stork-kubernetes-discovery/" /><author><name>Aurea Munoz</name></author><id>https://quarkus.io/blog/stork-kubernetes-discovery/</id><updated>2022-02-17T00:00:00Z</updated><content type="html">As we already described in the previous post, SmallRye Stork is a service discovery and client-side load-balancing framework that brings out-of-the-box integration with Kubernetes, among others. This post will explain this integration, how to configure Stork in a client-side microservice, and how it differs from the classic Kubernetes service discovery...</content><dc:creator>Aurea Munoz</dc:creator></entry><entry><title>Deploy JBoss EAP with RHEL using the Azure Marketplace offering</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/02/16/deploy-jboss-eap-rhel-using-azure-marketplace-offering" /><author><name>Yeray Borges Santana</name></author><id>e8153815-69eb-4baf-89fc-b96faf422b51</id><updated>2022-02-16T07:00:00Z</updated><published>2022-02-16T07:00:00Z</published><summary type="html">&lt;p&gt;This article shows how to use the &lt;a href="https://azuremarketplace.microsoft.com/marketplace/apps/redhat.jboss-eap-rhel"&gt;Microsoft Azure Marketplace offering&lt;/a&gt; of &lt;a href="https://developers.redhat.com/products/eap/download"&gt;Red Hat JBoss Enterprise Application Platform (JBoss EAP)&lt;/a&gt; to deploy a JBoss EAP server running on &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux (RHEL)&lt;/a&gt; to Azure virtual machines (VMs). JBoss EAP is an &lt;a href="https://developers.redhat.com/topics/open-source"&gt;open source&lt;/a&gt; application platform for building and deploying &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;enterprise Java&lt;/a&gt; applications. Azure is a very popular cloud service, and the JBoss EAP offering makes it easy to start using a powerful and familiar &lt;a data-linktype="external" href="https://jakarta.ee/"&gt;Jakarta EE&lt;/a&gt; runtime on Azure.&lt;/p&gt; &lt;h2&gt;JBoss Enterprise Application Platform on Azure Marketplace&lt;/h2&gt; &lt;p&gt;The Azure Marketplace offering of JBoss EAP offers three combinations of JBoss EAP and Red Hat Enterprise Linux:&lt;/p&gt; &lt;ol&gt;&lt;li&gt; &lt;p&gt;A standalone server running on an Azure Virtual Machine. This is the simplest case, with one JBoss EAP server running on Red Hat Enterprise Linux on a private virtual network with one subnet (Figure 1).&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/standalone.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/standalone.png?itok=LSMSicbl" width="382" height="340" alt="The simplest Azure deployment is a standalone single JBoss EAP instance." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. The simplest Azure deployment is a standalone single JBoss EAP instance. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;A cluster of JBoss EAP servers running on Azure VMs on a private virtual network with one subnet. You can choose the number of cluster members you want to deploy. This configuration uses an internal load balancer to distribute the incoming network traffic to your private network (Figure 2).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/multi.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/multi.png?itok=5e0nF98k" width="594" height="754" alt="Multiple JBoss EAP instances can run in a cluster with a load balancer to direct traffic." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. Multiple JBoss EAP instances can run in a cluster with a load balancer to direct traffic. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;An autoscale cluster server running on &lt;a href="https://azure.microsoft.com/en-us/services/virtual-machine-scale-sets/"&gt;Azure Virtual Machine Scale Set (VMSS)&lt;/a&gt;. This configuration is similar to the previous one, but can automatically increase or decrease the number of cluster members in response to demand (Figure 3).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/scale.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/scale.png?itok=0F9HdfoP" width="596" height="892" alt="Azure can also autoscale JBoss EAP instances." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3. Azure can also autoscale JBoss EAP instances. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/li&gt; &lt;/ol&gt;&lt;p&gt;The example in this article uses the Red Hat offering on Azure to create a cluster of two JBoss EAP instances. We expose the instances to the internet behind an Azure firewall and get access to the JBoss management command-line interface (CLI) of each instance from your local machine.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;ul&gt;&lt;li&gt; &lt;p&gt;An Azure account with an active subscription: If you don't have an Azure subscription, you can &lt;a data-linktype="external" href="https://azure.microsoft.com/pricing/free-trial"&gt;create an account for free&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;JBoss EAP: You need a Red Hat account with a Red Hat Subscription Management entitlement for JBoss EAP. The entitlement lets you download a version of JBoss EAP tested and certified by Red Hat. If you don't have EAP entitlement, sign up for a free developer subscription through the &lt;a data-linktype="external" href="https://developers.redhat.com/register"&gt;Red Hat Developer Subscription for Individuals&lt;/a&gt;. Once registered, you can find the necessary credentials (Pool IDs) at the &lt;a data-linktype="external" href="https://access.redhat.com/management/"&gt;Red Hat Customer Portal&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Azure CLI utility, which you can &lt;a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli"&gt;install from the Microsoft site&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Deploy a JBoss EAP cluster on an Azure VM&lt;/h2&gt; &lt;p&gt;The following steps describe how to deploy a JBoss EAP cluster on an Azure VM:&lt;/p&gt; &lt;ol&gt;&lt;li&gt; &lt;p&gt;Get the Azure Marketplace offering of JBoss EAP on Red Hat Enterprise Linux. Open the Azure portal and select the &lt;strong&gt;Create a resource&lt;/strong&gt; button, and then search for &lt;strong&gt;Red Hat JBoss Enterprise Application Platform (JBoss EAP)&lt;/strong&gt;. You will arrive at the overview page in Figure 4.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/offering.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/offering.png?itok=Hxe72C5h" width="1440" height="1084" alt="Azure has a JBoss EAP offering." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4. Azure has a JBoss EAP offering. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Select your desired software plan, which defines the license model combination of JBoss EAP and Red Hat Enterprise Linux. At the moment of writing, the following license models are available:&lt;/p&gt; &lt;ul&gt;&lt;li&gt; &lt;p&gt;Bring Your Own Subscription (BYOS): Use your existing Red Hat subscriptions to run Red Hat Products on Azure.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Pay As You Go (PYOS): Get billed periodically for usage by Microsoft.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt;&lt;p&gt;For this tutorial, we selected "JBoss EAP 7 (BYOS) on Red Hat Enterprise Linux 8 (PAYG) Clustered VM." Once you have selected your software plan, click the &lt;strong&gt;Create&lt;/strong&gt; button. You will be redirected to the &lt;strong&gt;Basics&lt;/strong&gt; configuration.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;You are going to connect to your cluster's VMs using an SSH public key, which you supply on the &lt;strong&gt;Basics&lt;/strong&gt; configuration tab. If you don't know how to create the SSH keys, you can follow the &lt;a href="http://go.microsoft.com/fwlink/?LinkId=2102401"&gt;Create and use an SSH public-private key pair for Linux VMs in Azure&lt;/a&gt; guide. As the terms indicate, you must keep your private key secret and use your public key on systems to which you want to connect.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;On the &lt;strong&gt;Basics&lt;/strong&gt; tab of the &lt;strong&gt;Create Red Hat JBoss Enterprise Application Platform (JBoss EAP)&lt;/strong&gt; page, enter or select the information listed in Table 1.&lt;/p&gt; &lt;table border="0" cellpadding="0" cellspacing="0" width="500"&gt;&lt;caption&gt;Table 1. Parameters for JBoss EAP instance.&lt;/caption&gt; &lt;thead&gt;&lt;tr&gt;&lt;th scope="col"&gt; &lt;p&gt;&lt;strong&gt;Setting&lt;/strong&gt;&lt;/p&gt; &lt;/th&gt; &lt;th scope="col"&gt; &lt;p&gt;&lt;strong&gt;Value&lt;/strong&gt;&lt;/p&gt; &lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Subscription&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Select your Azure subscription.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Resource group&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Select &lt;strong&gt;Create new&lt;/strong&gt; and enter &lt;code&gt;eap-cluster&lt;/code&gt; in the text box.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Region&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Choose the Azure region that's right for you.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Virtual Machine name&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Enter &lt;code&gt;eap-cluster-vm &lt;/code&gt;in the text box.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Availability set name&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Enter &lt;code&gt;eap-cluster-as &lt;/code&gt;in the text box.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Username&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;This is the Red Hat Enterprise Linux user account name. Enter &lt;code&gt;rheluser&lt;/code&gt;.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Authentication type&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;This setting configures how your Red Hat Enterprise Linux user account can be authenticated in your system. Select &lt;strong&gt;SSH Public Key&lt;/strong&gt;.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;SSH public key&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;This is the SSH public key for the Virtual Machines. Paste here the content of the public key you generated earlier.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;Select the &lt;strong&gt;Next: Virtual Machine Settings&lt;/strong&gt; button to navigate to the next tab.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;On the &lt;strong&gt;Virtual Machine Settings&lt;/strong&gt; tab, configure the number of machines that will be part of your cluster, the size of your VMs, and the virtual network and subnet where your cluster will be deployed. We use all the defaults in this article except for the virtual network and subnet.&lt;/p&gt; &lt;p&gt;Click the &lt;strong&gt;Create new&lt;/strong&gt; button in the &lt;strong&gt;Virtual Network&lt;/strong&gt; field to open the &lt;strong&gt;Create virtual network&lt;/strong&gt; dialog. Edit the virtual network name and the subnet names as shown in Figure 5.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/create_1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/create_1.png?itok=RlyLEpB-" width="1440" height="786" alt="Specify a name, subnet name, and address range." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5. Specify a name, subnet name, and address range. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;For the purposes of this example, the virtual network needs to have enough space to accommodate two subnets. One subnet will be private and the other will be public. At this step, you are defining only the private subnet. Later, when you add the Azure Firewall, you will need to create an additional subnet. So take both subnets into account at this stage. Use an address range for your virtual network and a private subnet large enough to allow you to create an additional subnet later.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Select the &lt;strong&gt;OK&lt;/strong&gt; button to accept the changes. The &lt;strong&gt;Create virtual network&lt;/strong&gt; dialog will close.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Click the &lt;strong&gt;Next: JBoss EAP Settings&lt;/strong&gt; button to navigate to the next tab.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;In the &lt;strong&gt;JBoss EAP Settings&lt;/strong&gt; tab, configure the JBoss EAP administrator username and password. Here you also supply information about the Red Hat subscription account that will be used to bring your license for your JBoss EAP product on Azure, in accordance with the BYOS model. Enter the information shown in Table 2.&lt;/p&gt; &lt;table border="0" cellpadding="0" cellspacing="0" width="500"&gt;&lt;caption&gt;Table 2. Parameters for JBoss EAP administrator.&lt;/caption&gt; &lt;thead&gt;&lt;tr&gt;&lt;th scope="col"&gt; &lt;p&gt;&lt;strong&gt;Setting&lt;/strong&gt;&lt;/p&gt; &lt;/th&gt; &lt;th scope="col"&gt; &lt;p&gt;&lt;strong&gt;Value&lt;/strong&gt;&lt;/p&gt; &lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;JBoss EAP Admin username&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Enter the name of the JBoss EAP administrator user: For example, &lt;code&gt;eapuser&lt;/code&gt;. You will log in to the JBoss EAP CLI later as this user.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;JBoss EAP password&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Enter the EAP admin password and confirm it. It must have a minimum of twelve characters.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;RHSM username&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Enter your Subscription Manager user account.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;RHSM password&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Enter your Subscription Manager password and confirm it.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;RHSM Pool ID with EAP entitlement&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Enter the Subscription Manager Pool ID where the JBoss EAP product is available.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;Select the &lt;strong&gt;Next: Review + create&lt;/strong&gt; button. All the supplied information will be immediately validated and a summary report will be shown.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;If you are fine with the summary, select the &lt;strong&gt;Create&lt;/strong&gt; button to deploy all the resources in Azure. The deployment might take a few minutes. Behind the scenes, the desired number of VMs will be created and the JBoss EAP server will be installed on those machines via RPM packages. Your Subscription Manager BYOS subscription will be used to download and install the JBoss EAP server on your Red Hat Enterprise Linux VMs. The default JBoss EAP server configuration will be modified accordingly, to make the server run properly on Azure.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;When your deployment finishes, you will see a summary of all the resources created automatically.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Verify the cluster data replication&lt;/h2&gt; &lt;p&gt;On each JBoss EAP server, the default multi-VM configuration of the Red Hat offering deploys a demo application that you can use to verify that your cluster is working properly. However, at this moment, we have two Red Hat Enterprise Linux virtual machines running on a private virtual network on Azure, and neither of those resources is accessible externally. In addition, the configured load balancer is an internal load balancer. It is not suitable for directly exposing your applications to external access by adding a public IP address. That restriction is intentional because it makes the default configuration secure without exposing any element to the outside world. It is up to you to decide what you want to expose and how. The best configuration choice depends considerably on your needs and what you are trying to achieve.&lt;/p&gt; &lt;p&gt;Assuming you want to access your cluster externally, in the following sections, we will explore one way to gain access to your JBoss instances by adding an Azure firewall.&lt;/p&gt; &lt;p&gt;If you don't want to expose your private network to the public, you have also multiple options: For example, you can &lt;a href="https://docs.microsoft.com/azure/virtual-machines/windows/quick-create-portal#create-virtual-machine"&gt;deploy a Windows VM&lt;/a&gt; on your private network and connect to it via &lt;a href="https://docs.microsoft.com/en-us/azure/bastion/bastion-overview"&gt;Azure Bastion&lt;/a&gt;. Once you have logged into your Windows machine, you will get access to your JBoss EAP cluster machines from there.&lt;/p&gt; &lt;h2&gt;Expose the cluster demo application to the internet&lt;/h2&gt; &lt;p&gt;Our goal is to get access from the public internet to the demo application deployed in your cluster. To do so, you will deploy an Azure firewall and place it in front of your internal load balancer so you can access your web applications externally in a secure way.&lt;/p&gt; &lt;p&gt;In the following sections, you will use the Azure CLI on a Linux machine to add and configure the required resources. In addition, you have to ensure that all your Azure CLI commands are created for the same location you used when you created the JBoss EAP cluster. You can handle the location by initializing an environment variable. That allows you to copy and paste the commands shown in this article without worrying about altering them to reflect your location.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; At the moment of writing, some commands related to the firewall configuration are in preview mode, so they might change slightly by the time you are reading this article.&lt;/p&gt; &lt;p&gt;This article assumes you have created an environment variable named &lt;code&gt;LOCATION&lt;/code&gt; to hold the location you used when creating your JBoss EAP resources. If you don't remember the location, grab it from your resource group by executing the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ LOCATION=$(az group show --name eap-cluster --query 'location' --output tsv)&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Set up the public IP address and firewall&lt;/h2&gt; &lt;p&gt;Azure Firewall is a managed, cloud-based network security service that protects your Azure Virtual Network resources. You have to create three sets of resources to make it work:&lt;/p&gt; &lt;ul&gt;&lt;li&gt; &lt;p&gt;A public IP address, to make your service accessible from the internet.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Security policies, which are collections of rules that allow inbound traffic to your Azure virtual network. These rules need to be added by creating three nested elements:&lt;/p&gt; &lt;ul&gt;&lt;li&gt; &lt;p&gt;Rule collection groups: Sets of rule collections of any type. These are useful to group your rules in a logical way, based on a similar priority.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Rule collections: Sets of rules of the same type, which can apply to a DNAT, network, or application. We will add DNAT rules to translate the external requests arriving at the HTTP port.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Rules: Actual rules defining what to do when a request arrives at your public IP address. In this article, the security policy accepts TCP traffic that arrives at your public IP address at port 80, and translates the destination to the internal IP address of your load balancer, which is also listening at port 80. The load balancer redirects the incoming traffic from port 80 to port 8080 on each VM, choosing healthy VMs.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;The firewall resource itself, which is deployed on a different subnet. The firewall uses the defined security policies to check whether inbound or outbound traffic is allowed.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Create a public IP address&lt;/h3&gt; &lt;p&gt;Let's start by creating a public IP address:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Use &lt;a href="https://docs.microsoft.com/en-us/cli/azure/network/public-ip#az_network_public_ip_create"&gt;az network public-ip create&lt;/a&gt; to create the address: &lt;pre&gt; &lt;code class="language-bash"&gt;$ az network public-ip create \ --resource-group eap-cluster \ --location $LOCATION \ --name eap-cluster-public-ip \ --dns-name eapclusterdemo \ --sku Standard&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The DNS name assigned to the public IP address is &lt;code&gt;eapclusterdemo.$LOCATION.cloudapp.azure.com&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Create the firewall policy resource with &lt;a href="https://docs.microsoft.com/en-us/cli/azure/network/firewall/policy?view=azure-cli-latest#az_network_firewall_policy_create"&gt;az network firewall policy create&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ az network firewall policy create \ --name eap-cluster-fw-policy \ --resource-group eap-cluster \ --location $LOCATION&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Create a rule collection group to hold your rule collections with &lt;a href="https://docs.microsoft.com/en-us/cli/azure/network/firewall/policy/rule-collection-group?view=azure-cli-latest#az_network_firewall_policy_rule_collection_group_create"&gt;az network firewall policy rule-collection-group create&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ az network firewall policy rule-collection-group create \ --name eap-cluster-rule-collection-group \ --policy-name eap-cluster-fw-policy \ --priority 30000 \ --resource-group eap-cluster&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Create a DNAT rule collection to hold all the rules related to web traffic. In the same command, you can also create the rule itself. Our rule is pretty simple: It allows HTTP traffic from any IP address to our public IP address and translates the specified port from 80 to the internal load balancer IP address. To accomplish this transformation, you need to know the public IP address and the internal load balancer IP address. Grab them by using the following commands:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;LOAD_BALANCER_IP=$(az network lb show \ --name jbosseap-lb \ --resource-group eap-cluster \ --query 'frontendIpConfigurations[].privateIpAddress' --output tsv) AZURE_PUBLIC_IP=$(az network public-ip show \ --name eap-cluster-public-ip \ --resource-group eap-cluster \ --query 'ipAddress' --output tsv)&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Create the DNAT rule collection and rule with &lt;a href="https://docs.microsoft.com/en-us/cli/azure/network/firewall/policy/rule-collection-group/collection?view=azure-cli-latest#az_network_firewall_policy_rule_collection_group_collection_add_nat_collection"&gt;az network firewall policy rule-collection-group collection add-nat-collection&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ az network firewall policy rule-collection-group collection add-nat-collection \ --name http-web-collection \ --collection-priority 30000 \ --policy-name eap-cluster-fw-policy \ --resource-group eap-cluster \ --rule-collection-group-name eap-cluster-rule-collection-group \ --action DNAT \ --rule-name inbound_web_trafic \ --description "Allow inbound Web traffic to the internal Load Balancer" \ --source-addresses "*" \ --destination-addresses $AZURE_PUBLIC_IP \ --destination-ports 80 \ --translated-address $LOAD_BALANCER_IP \ --translated-port 80 \ --ip-protocols TCP&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;That's all you need to do regarding the firewall security policy. Now create the firewall resource itself with &lt;a href="https://docs.microsoft.com/en-us/cli/azure/network/firewall?view=azure-cli-latest#az_network_firewall_create"&gt;az network firewall create&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ az network firewall create \ --name eap-cluster-fw \ --resource-group eap-cluster \ --firewall-policy eap-cluster-fw-policy \ --location $LOCATION&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;To configure the firewall to protect your virtual network, you must create a subnet named &lt;strong&gt;AzureFirewallSubnet&lt;/strong&gt;. You can create it with &lt;a href="https://docs.microsoft.com/en-us/cli/azure/network/vnet/subnet?view=azure-cli-latest#az_network_vnet_subnet_create"&gt;az network vnet subnet create&lt;/a&gt;. At this step, pay attention to the address prefix you have to use. You probably will need to review what addresses you used when you were creating the JBoss EAP cluster. The subnet you need to create at this step is the public subnet:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ az network vnet subnet create \ --name AzureFirewallSubnet \ --resource-group eap-cluster \ --vnet-name eap-cluster-vnet \ --address-prefixes 10.0.1.0/24&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The firewall will be working on the 10.0.1.0/24 subnet, whereas your private subnet is on 10.0.0.0/24. The virtual network is 10.0.0.0/16.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Finally, configure the firewall to use the public IP address and your virtual network through &lt;a href="https://docs.microsoft.com/en-us/cli/azure/network/firewall/ip-config?view=azure-cli-latest#az_network_firewall_ip_config_create"&gt;az network firewall ip-config create&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ az network firewall ip-config create \ --firewall-name eap-cluster-fw \ --name eap-cluster-fw-ip \ --public-ip-address eap-cluster-public-ip \ --resource-group eap-cluster \ --vnet-name eap-cluster-vnet&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This operation takes a few minutes to complete. Once done, you will have access to the demo application deployed on the EAP servers.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Interact with the demo application&lt;/h2&gt; &lt;p&gt;At this point, your VMs are exposed on the internet, protected by a firewall. You should have access to them via the fully qualified domain name (FQDN) of your Azure Virtual Network public IP address. You can get the FQDN by issuing the following command:&lt;/p&gt; &lt;ol&gt;&lt;li&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ az network public-ip show \ --resource-group eap-cluster \ --name eap-cluster-public-ip \ --query 'dnsSettings.fqdn'&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Open your favorite browser and navigate to &lt;code&gt;http://&lt;DNS FQDN&gt;/eap-session-replication&lt;/code&gt;. The demo application's landing page will be displayed.&lt;/p&gt; &lt;p&gt;You can use this application to verify that the cluster is working as expected through the following steps:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Increment the counter several times. The demo application shows the VM's private IP address that served your last request (Figure 7).&lt;/li&gt; &lt;li&gt; &lt;p&gt;From the Azure portal, locate the VM with that IP address and stop it. You can find the VM's private IP address by inspecting the &lt;strong&gt;Networking&lt;/strong&gt; settings on your VM resource (Figure 6).&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="JBoss EAP VMo private IP" data-entity-type="file" data-entity-uuid="59ac40eb-baea-4ac7-965d-edd4b4af6561" src="https://developers.redhat.com/sites/default/files/inline-images/vm-0-networking.png" width="2390" height="922" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 6. The VM's resources page shows the public IP address in the Networking settings.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;li&gt;Go back to the demo application and select &lt;strong&gt;Refresh&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt; &lt;p&gt;You will get a response served by the other VM (Figure 8), which returns the same session ID and counter value.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Going through the steps in the previous list demonstrates that your session information is replicated in the cluster (Figures 7 and 8). If the process succeeds, restart the stopped VM so you can continue with the next section.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/demo0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/demo0.png?itok=7eswvvP8" width="600" height="776" alt="Azure displays session information for VM0." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7. Azure displays session information for VM0. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/demo1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/demo1.png?itok=pcc6AgIG" width="600" height="773" alt="Azure displays session information for VM1." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8. Azure displays session information for VM1. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Deploy your applications via the JBoss Management CLI&lt;/h2&gt; &lt;p&gt;In addition to the HTTP ports, you can add DNAT rules to access the JBoss EAP CLI on each server instance. Access to the CLI allows you to configure the servers further and deploy applications. Similar to what you did to expose the HTTP port, the following steps expose the SSH port of each VM through the firewall. You will use the private key of the SSH key pair you used when you created the cluster. To increase the level of security, you are allowing only connections coming from your local machine.&lt;/p&gt; &lt;p&gt;First of all, grab your public IP address (multiple sites on the internet such as &lt;a href="https://www.whatismyip.com/"&gt;whatismyip.com&lt;/a&gt; can give you this information), the public IP address of your cluster in Azure, and the private IP addresses of each VM. Save these addresses in variables, for instance:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;LOCAL_PUBLIC_IP="71.145.22.216" AZURE_PUBLIC_IP=$(az network public-ip show \ --name eap-cluster-public-ip \ --resource-group eap-cluster \ --query 'ipAddress' --output tsv) IP_VM0=$(az network nic show \ --name jbosseap-server-nic0 \ --resource-group eap-cluster \ --query 'ipConfigurations[].privateIpAddress' \ --output tsv) IP_VM1=$(az network nic show \ --name jbosseap-server-nic1 \ --resource-group eap-cluster \ --query 'ipConfigurations[].privateIpAddress' \ --output tsv)&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: By default, the network interfaces are created by appending the index of the VM that belongs to the cluster to &lt;code&gt;jbosseap-server-nic&lt;/code&gt; . Therefore, if you have created a cluster with two machines, the network interface names of those machines are &lt;code&gt;jbosseap-server-nic0&lt;/code&gt; and &lt;code&gt;jbosseap-server-nic1&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Add a new firewall rule collection to group the rules related to the SSH ports and two rules that translate the traffic coming from port 10022 to port 22 for the first Virtual Machine (VM0) and from port 20022 to port 22 for the other Virtual Machine (VM1). Notice that you are also specifying that the only valid source is your public IP address:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Create the rule for the VM0: &lt;pre&gt; &lt;code class="language-bash"&gt;$ az network firewall policy rule-collection-group collection add-nat-collection \ --name ssh-collection \ --collection-priority 30010 \ --policy-name eap-cluster-fw-policy \ --resource-group eap-cluster \ --rule-collection-group-name eap-cluster-rule-collection-group \ --action DNAT \ --rule-name inbound_ssh_trafic_vm0 \ --description "Allow inbound SSH traffic to VM 0" \ --source-addresses $LOCAL_PUBLIC_IP \ --destination-addresses $AZURE_PUBLIC_IP \ --destination-ports 10022 \ --translated-address $IP_VM0 \ --translated-port 22 \ --ip-protocols TCP&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Create the rule for the VM1: &lt;pre&gt; &lt;code class="language-bash"&gt;$ az network firewall policy rule-collection-group collection rule add \ --collection-name ssh-collection \ --name inbound_ssh_trafic_vm1 \ --policy-name eap-cluster-fw-policy \ --rule-collection-group-name eap-cluster-rule-collection-group \ --resource-group eap-cluster \ --rule-type NatRule \ --description "Allow inbound SSH traffic to VM 1" \ --source-addresses $LOCAL_PUBLIC_IP \ --destination-addresses $AZURE_PUBLIC_IP \ --destination-ports 20022 \ --translated-address $IP_VM1 \ --translated-port 22 \ --ip-protocols TCP&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Once you have created the rules, you can gain access to the VMs using SSH with the user name of your Red Hat Enterprise Linux VMs (&lt;code&gt;rheluser&lt;/code&gt; in this article) and your public key:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ssh -i eap-cluster-rsa rheluser@${AZURE_PUBLIC_IP} -p 10022 $ ssh -i eap-cluster-rsa rheluser@${AZURE_PUBLIC_IP} -p 20022&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And on each SSH session, you can get onto the JBoss CLI server by issuing the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[rheluser@eap-cluster-vm0 ~]$ $EAP_HOME/wildfly/bin/jboss-cli.sh -c -u=eapuser Authenticating against security realm: ManagementRealm Password: [standalone@localhost:9990 /]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This &lt;code&gt;eapuser&lt;/code&gt; user and its password are the credentials configured when you created the cluster.&lt;/p&gt; &lt;p&gt;Since you can connect to your VMs using SSH, you can also copy files securely using Secure Copy (&lt;code&gt;scp&lt;/code&gt;). To deploy an application in your cluster, you can copy the application to a known directory on the remote VMs, and then deploy the application by using the JBoss EAP CLI. For example, suppose you have a local application named &lt;code&gt;helloworld.war&lt;/code&gt;. You can deploy it by issuing the following commands:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ scp -i eap-cluster-rsa -P 10022 helloworld.war rheluser@${AZURE_PUBLIC_IP}:/tmp helloworld.war 100% 6495 109.1KB/s 00:00 $ ssh -i eap-cluster-rsa rheluser@${AZURE_PUBLIC_IP} -p 10022 [rheluser@eap-cluster-vm0 ~]$ $EAP_HOME/wildfly/bin/jboss-cli.sh -c -u=eapuser Authenticating against security realm: ManagementRealm Password: [standalone@localhost:9990 /] deploy /tmp/helloworld.war [standalone@localhost:9990 /] exit [rheluser@eap-cluster-vm0 ~]$ exit logout Connection to 20.90.187.110 closed.&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Repeat the same commands for VM1 by using port 20022 in place of 10022. Your application will be deployed and available at &lt;code&gt;http://&lt;DNS FQDN&gt;/your-application-web-context&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;For debugging, you can find the server.log at &lt;code&gt;/opt/rh/eap7/root/usr/share/wildfly/standalone/log/server.log&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Clean up resources&lt;/h2&gt; &lt;p&gt;To delete all the resources created on Azure, open the &lt;strong&gt;eap-cluster&lt;/strong&gt; resource group and select &lt;strong&gt;Delete resource group&lt;/strong&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Red Hat accounts make it easy to use JBoss EAP on Azure with modern, production-level features such as load balancing. Try out different configurations and scale your applications.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/02/16/deploy-jboss-eap-rhel-using-azure-marketplace-offering" title="Deploy JBoss EAP with RHEL using the Azure Marketplace offering"&gt;Deploy JBoss EAP with RHEL using the Azure Marketplace offering&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Yeray Borges Santana</dc:creator><dc:date>2022-02-16T07:00:00Z</dc:date></entry><entry><title>Write Kubernetes in Java with the Java Operator SDK</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/02/15/write-kubernetes-java-java-operator-sdk" /><author><name>Christophe Laprun</name></author><id>1516637a-e905-4bc1-b6e6-ed887b069697</id><updated>2022-02-15T07:00:00Z</updated><published>2022-02-15T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://javaoperatorsdk.io"&gt;Java Operator SDK&lt;/a&gt;, or JOSDK, is an &lt;a href="https://developers.redhat.com/topics/open-source"&gt;open source&lt;/a&gt; project that aims to simplify the task of creating &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; Operators using &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt;. The project was started by &lt;a href="https://container-solutions.com"&gt;Container Solutions&lt;/a&gt;, and Red Hat is now a major contributor.&lt;/p&gt; &lt;p&gt;In this article, you will get a brief overview of what Operators are and why it could be interesting to create them in Java. A future article will show you how to create a simple Operator using JOSDK.&lt;/p&gt; &lt;p&gt;As you can guess, this series of articles is principally targeted at Java developers interested in writing Operators in Java. You don't have to be an expert in Operators, Kubernetes, or &lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt;. However, a basic understanding of all these topics will help. To learn more, I recommend reading Red Hat Developer's &lt;a href="https://developers.redhat.com/articles/2021/06/11/kubernetes-operators-101-part-1-overview-and-key-features"&gt;Kubernetes Operators 101 series&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Kubernetes Operators: A brief introduction&lt;/h2&gt; &lt;p&gt;Kubernetes has become the &lt;em&gt;de facto&lt;/em&gt; standard platform for deploying cloud applications. At its core, Kubernetes rests on a simple idea: The user communicates the state in which they want a cluster to be, and the platform will strive to realize that goal. A user doesn't need to tell Kubernetes the steps to get there; they just need to specify what that desired end state should look like. Typically, this involves providing the cluster with a materialized version of this desired state in the form of JSON or YAML files, sent to the cluster for consideration using the &lt;a href="https://kubernetes.io/docs/reference/kubectl/overview/"&gt;&lt;code&gt;kubectl&lt;/code&gt;&lt;/a&gt; tool. Assuming the desired state is valid, once it's on the cluster it will be handled by &lt;em&gt;controllers.&lt;/em&gt; Controllers are processes that run on the cluster and monitor the associated resources to reconcile their actual state with the state desired by the user.&lt;/p&gt; &lt;p&gt;Despite this conceptual simplicity, actually operating a Kubernetes cluster is not a trivial undertaking for non-expert users. Notably, deploying and configuring Kubernetes applications typically requires creating several resources, bound together by sometimes complex relations. In particular, developers who might not have experience on the operational side of things often struggle to move their applications from their local development environment to their final cloud destination. Reducing this complexity would therefore reap immense benefits for users, particularly by encapsulating the required operational knowledge in the form of &lt;a href="https://developers.redhat.com/topics/automation"&gt;automation&lt;/a&gt; that could be interacted with at a higher level by users less familiar with the platform. This is what Kubernetes &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/"&gt;Operators&lt;/a&gt; were developed to achieve.&lt;/p&gt; &lt;h3&gt;Custom Resources&lt;/h3&gt; &lt;p&gt;Kubernetes comes with an extension mechanism in the form of &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"&gt;custom resources &lt;/a&gt; (CRs), which allow users to extend the Kubernetes platform in a way similar to how the core platform is implemented. There is not much formal difference between how native and custom resources are handled: both define domain-specific languages (DSLs) controlling one specific aspect of the platform realized by the YAML or JSON representations of the resources. While native resources control aspects that are part of the platform via their associated controllers, custom resources provide another layer on top of these native resources—allowing users to define higher-level abstractions, for example.&lt;/p&gt; &lt;p&gt;However, the platform doesn't know the first thing about these custom resources, so users must first register a controller with the platform to handle them. The combination of a custom resource-defined DSL and an associated controller enables users to define vocabularies that are closer to their business model. They can focus on business-specific aspects of their application rather than worrying about how a specific state will be realized on the cluster; the latter task falls under the responsibility of the associated controller. This pattern makes it possible to encapsulate the operational knowledge implemented by the associated controller behind the DSL provided by the custom resource. That's what Operators are: implementations of this useful pattern.&lt;/p&gt; &lt;p&gt;Operators are therefore quite attractive for those who want to reduce the knowledge required to deploy applications, but they also automate repetitive steps. They offer organizations the possibility of encapsulating business rules or processes behind a declarative "language" expressed by custom resources using a vocabulary tailored to the task at hand instead of dealing with Kubernetes-native resources that are foreign to less technical users. Once an Operator is installed and configured on a cluster, the logic and automation it provides are accessible to cluster users, who only have to deal with the associated DSL.&lt;/p&gt; &lt;h2&gt;Why write Operators in Java?&lt;/h2&gt; &lt;p&gt;Kubernetes and its ecosystem are written in the &lt;a href="https://developers.redhat.com/topics/go"&gt;Go programming language&lt;/a&gt;, and Operators traditionally have been as well. While it's not necessary to write everything in the same language, it's also a reality that the ecosystem is optimized for Go developers. To be fair, Go is well suited for this task: the language is relatively easy to learn and offers good runtime characteristics both in terms of memory and CPU usage. Moreover, several Go projects aim to make the Operator writing process easy:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://sdk.operatorframework.io/"&gt;&lt;code&gt;operator-sdk&lt;/code&gt;&lt;/a&gt; and its command line tool help developers get started faster&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/kubernetes/client-go/"&gt;&lt;code&gt;client-go&lt;/code&gt;&lt;/a&gt; facilitates programmatic interactions with the Kubernetes API server&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/kubernetes/apimachinery"&gt;&lt;code&gt;apimachinery&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://http://github.com/kubernetes/controller-runtime"&gt;&lt;code&gt;controller-runtime&lt;/code&gt;&lt;/a&gt; offer useful utilities and patterns&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;If Go is so good for writing Operators, why would anyone want to do it in Java? For one thing, Java is the language in which a significant number of enterprise applications are written. These applications are traditionally very complex by nature, and companies that rely on them would benefit from simplified ways to deploy and operate them at scale on Kubernetes clusters.&lt;/p&gt; &lt;p&gt;Moreover, the &lt;a href="https://developers.redhat.com/topics/devops"&gt;DevOps&lt;/a&gt; philosophy mandates that developers should also be responsible for deployment to production, maintenance, and other operational aspects of their application's lifecycle. From that perspective, being able to use the same language during all stages of the lifecycle is an attractive proposition.&lt;/p&gt; &lt;p&gt;Finally, Java-focused companies looking to write Kubernetes Operators want to capitalize on the existing wealth of Java experience among their developers. If developers can ramp up quickly in a programming language they already know rather than investing time and energy learning a new one, that offers a non-negligible advantage.&lt;/p&gt; &lt;h2&gt;Java in the cloud?&lt;/h2&gt; &lt;p&gt;That said, if writing Operators in Java offers so many benefits, why aren't more companies doing it? The first reason that comes to mind is that, compared to Go, Java has traditionally been pretty weak when it comes to deploying to the cloud. Indeed, Java is a platform that has been honed over decades for performance on long-running servers. In that context, memory usage or slow startup times are usually not an issue. This particular drawback has been progressively addressed over time, but the fact remains that a typical Java application will use more memory and start more slowly than a Go application. This matters quite a bit in a cloud environment, in which the pod where your application is running can be killed at any time (the &lt;a href="https://www.redhat.com/en/blog/container-tidbits-does-pets-vs-cattle-analogy-still-apply"&gt;cattle versus pet approach&lt;/a&gt;), and where you might need to scale up quickly (in &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;serverless&lt;/a&gt; environments in particular). Memory consumption also affects deployment density: the more memory your application consumes, the more difficult it is to deploy several instances of it on the same cluster where resources are limited.&lt;/p&gt; &lt;p&gt;Several projects have been initiated to improve Java's suitability for cloud environments, among which is &lt;a href="https://quarkus.io"&gt;Quarkus&lt;/a&gt;, on which this series of articles will focus. The Quarkus project describes itself as "a Kubernetes-native Java stack tailored for OpenJDK HotSpot and GraalVM, crafted from the best of breed Java libraries and standards." By moving much of the processing that is typically done by traditional Java stacks at runtime (e.g., annotation processing, properties file parsing, introspection) to build time, Quarkus improves Java application performance in terms of both consumed memory and startup time. By leveraging the &lt;a href="https://graalvm.org"&gt;GraalVM&lt;/a&gt; project, it also enables easier native compilation of Java applications, making them competitive with Go applications and almost removing runtime characteristics from the equation.&lt;/p&gt; &lt;h2&gt;What about framework support?&lt;/h2&gt; &lt;p&gt;However, as we've already noted, even if we're not taking runtime characteristics into account, Go is an attractive language in which to write Operators, thanks in no small part to the framework ecosystem it offers to support such a task. While there are Java clients that rival the &lt;code&gt;client-go&lt;/code&gt; project to help with interacting with the Kubernetes server, these clients only provide low-level abstractions, while the Go ecosystem provides higher-level frameworks and utilities targeted at Operator developers.&lt;/p&gt; &lt;p&gt;That's where JOSDK comes in, offering a framework comparable to what &lt;code&gt;controller-runtime&lt;/code&gt; offers to Go developers, but tailored for Java developers and using Java idioms. JOSDK aims to ease the task of developing Java Operators by providing a framework that deals with low-level events and implements best practices and patterns, thus allowing developers to focus on their Operator's business logic instead of worrying about the low-level operations required to interact with the Kubernetes API server.&lt;/p&gt; &lt;p&gt;Recognizing that Quarkus is particularly well suited for deploying Java applications, and more specifically Operators, in the cloud, Red Hat has taken JOSDK one step further by integrating it into &lt;a href="https://github.com/quarkiverse/quarkus-operator-sdk"&gt;&lt;code&gt;quarkus-operator-sdk&lt;/code&gt;, a Quarkus extension&lt;/a&gt; that simplifies the Java Operator development task even further by focusing on the development experience aspects. Red Hat has also contributed a plug-in for the &lt;a href="https://sdk.operatorframework.io/docs/cli/operator-sdk/"&gt;&lt;code&gt;operator-sdk&lt;/code&gt; command line tool&lt;/a&gt; to allow quick scaffolding of Java Operator projects using JOSDK and its Quarkus extension.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This concludes the first part of this series exploring writing Operators using JOSDK and Quarkus. You got a sense of the motivation for these projects and saw why it is interesting and useful to write Operators in Java.&lt;/p&gt; &lt;p&gt;In the next part of this series, you'll dive into JOSDK's concepts in greater detail and start implementing a Java Operator of your own using its Quarkus extension and the &lt;code&gt;operator-sdk&lt;/code&gt; command-line tool.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/02/15/write-kubernetes-java-java-operator-sdk" title="Write Kubernetes in Java with the Java Operator SDK"&gt;Write Kubernetes in Java with the Java Operator SDK&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Christophe Laprun</dc:creator><dc:date>2022-02-15T07:00:00Z</dc:date></entry><entry><title type="html">Getting started with Stork Service Discovery on Quarkus</title><link rel="alternate" href="http://www.mastertheboss.com/soa-cloud/quarkus/getting-started-with-stork-service-discovery-on-quarkus/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/soa-cloud/quarkus/getting-started-with-stork-service-discovery-on-quarkus/</id><updated>2022-02-14T07:17:50Z</updated><content type="html">In modern microservices architectures, services have dynamically assigned locations. Therefore, it’s essential to integrate Service Discovery as part of the picture. In this article you will learn how to leverage Service Discovery using Smallrye Stork framework on top of a Quarkus reactive application. Service discovery in a nutshell Before we dig into this tutorial, we ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry></feed>
